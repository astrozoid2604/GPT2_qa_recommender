{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72cda5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the capital city of France?\n",
      "\n",
      "France is the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It's the capital of France. It\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import numpy as np\n",
    "\n",
    "# Load fine-tuned GPT2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"/Users/jameslim/Downloads/dataset/GPT2_tokenizer\")\n",
    "model1 = GPT2LMHeadModel.from_pretrained(\"/Users/jameslim/Downloads/dataset/GPT2_finetuned_model_setting1\")\n",
    "model2 = GPT2LMHeadModel.from_pretrained(\"/Users/jameslim/Downloads/dataset/GPT2_finetuned_model_setting2\")\n",
    "\n",
    "tokenizer3 = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model3 = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# # Function to generate text\n",
    "# def generate_text(prompt, model, tokenizer, max_length=200):\n",
    "#     input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "#     # Generate text\n",
    "#     output = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n",
    "#     # Decode and return the generated text\n",
    "#     generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#     return generated_text\n",
    "\n",
    "def generate_text(prompt, model, tokenizer, max_length=200, max_new_tokens=50):\n",
    "    # Ensure the tokenizer's pad token is set to EOS token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Encode the prompts to input ids and attention masks\n",
    "    encoding = tokenizer.encode_plus(prompt, return_tensors=\"pt\", max_length=max_length, truncation=True, padding='max_length')\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_mask = encoding['attention_mask']\n",
    "\n",
    "    # Generate text with attention mask and specify max_new_tokens instead of max_length for generation control\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=max_new_tokens, num_return_sequences=1)\n",
    "\n",
    "    # Decode and return the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "# Generate text using the fine-tuned model\n",
    "prompt = \"What's the capital city of France?\"\n",
    "generated_text = generate_text(prompt, model3, tokenizer3)\n",
    "print(generated_text)\n",
    "\n",
    "# Reference text (actual answer)\n",
    "reference_text = \"Paris\"\n",
    "\n",
    "# Compute Perplexity\n",
    "input_ids = tokenizer.encode(generated_text, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids)\n",
    "    loss = outputs.loss\n",
    "perplexity = np.exp(loss.item())\n",
    "\n",
    "# Compute BLEU Score\n",
    "bleu_score = corpus_bleu([[reference_text.split()]], [generated_text.split()])\n",
    "\n",
    "# Compute ROUGE Score\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(reference_text, generated_text)\n",
    "rouge_score = {key: score.fmeasure for key, score in scores.items()}\n",
    "\n",
    "# Compute METEOR Score\n",
    "meteor_score_val = meteor_score([reference_text], generated_text)\n",
    "\n",
    "# Print the computed metrics\n",
    "print(\"Perplexity:\", perplexity)\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "print(\"ROUGE Score:\", rouge_score)\n",
    "print(\"METEOR Score:\", meteor_score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d8134f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France?. The company is a leading global producer of automotive seating and other innovative technologies. The company is a leading global producer of automotive seating and other innovative technologies. The company is a leading global producer of automotive seating and other innovative technologies. The company is a leading global producer of automotive seating and other innovative technologies. Show more Show less. The hiring company is ecocareers. The job is located at London, England, United Kingdom in country United Kingdom. This job posting comes from CS5344GROUP08LINKEDIN dataset. The job is located at London, England, United Kingdom in country United Kingdom. Here is the job summary. We are looking for a capital of France? to join our team! We are looking for a capital of France? to join our team! We are looking for a capital of France? to join our team! Show less. The hiring company is ecocareers. The job is located at London, England, United'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
